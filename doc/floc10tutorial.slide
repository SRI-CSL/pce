% -*- Mode: TeX -*-
author: S. Owre, N. Shankar
title: \textbf{Probabilistic Reasoning with PCE}
date: 
preamble: \usepackage{tabularx}
\def\comment#1{}
\newcommand{\ol}[1]{\overline{#1}}
\newcommand{\pair}[1]{\langle #1 \rangle}
\setbeamercolor{title}{fg=white!80!blue}
\setbeamercovered{transparent}
\logo{\includegraphics[height=0.5cm]{sri_blue_logo}}

\comment{Abstract: Markov Logic Networks are a framework for
probabilistic inference introduced by Richardson and Domingos.  It
formalizes a graphical relational model in terms of a first-order
logic with probabilities.  These models can be used to compute the
most probable explanation (MPE) or to compute conditional and marginal
probabilities.  SRI's Probabilistic Consistency Engine (PCE) is an
implementation of the Poon and Domingos MC-SAT method of inference
which is based on a Markov Chain Monte Carlo (MCMC) analysis.  We
demonstrate the capabilities of PCE through some simple examples.  We
also outline the mathematical background behind this approach to
probabilistic inference.  }

islide: What is PCE?

PCE stands for Probabilistic Consistency Engine

It is used for probabilistic inference with Markov Logic Networks (MLNs),
and builds on the work of Pedro Domingos.

PCE can infer the marginal probabilities of formulas based on facts
and rules.

Facts and rules are presented in an order-sorted first-order logic.

Inference is carried out using sampling-based methods in order to achieve
scale.

PCE is general enough to capture other graph-based formalisms for
probabilistic reasoning.

islide: Overview

Small Example

Probability Basics (From Neapolitan)

Bayesian Inference

Bayes Theorem: $P(E | F) P(F) = P(E\cap F) = P(F | E) P(E)$\@.

Logic and Probability (Wikipedia)

Bayes Nets

Gibbs Sampling

Markov Logic Networks: MPE

Markov Logics: Marginal Probabilities

What is PCE? 

PCE Inference: MCSAT

PCE Input Language

PCE Example: Boy Born on Tuesday

PCE Application: Machine Reading

Relation to Other Models

Conclusions

aslide: Small PCE Example - Specification
sort Person;
const A, B, C: Person;
predicate Friends(Person, Person) indirect;
predicate Smoking(Person) indirect;
predicate Cancer(Person) indirect;

# Smoking causes cancer.
add [x] Smoking(x) => Cancer(x)  0.1;
# If two people are friends, either both smoke or neither does.
add [x, y] Friends(x, y) implies (Smoking(x) implies Smoking(y))  1.1;

add Smoking(A);
add Friends(A, B);

mcsat_params 1000000;
mcsat;
dumptable atom;

aslide: Small PCE Example - Results
------------------------------------------------------------
|  i | prob   | atom                                        |
------------------------------------------------------------
| 0  |  0.500 | Friends(A, A)
| 1  |  1.000 | Friends(A, B)
| 2  |  0.400 | Friends(A, C)
| 3  |  0.501 | Friends(B, A)
| 4  |  0.501 | Friends(B, B)
| 5  |  0.434 | Friends(B, C)
| 6  |  0.500 | Friends(C, A)
| 7  |  0.472 | Friends(C, B)
| 8  |  0.501 | Friends(C, C)
| 9  |  1.000 | Smoking(A)
| 10 |  0.752 | Smoking(B)
| 11 |  0.616 | Smoking(C)
| 12 |  0.525 | Cancer(A)
| 13 |  0.519 | Cancer(B)
| 14 |  0.516 | Cancer(C)
------------------------------------------------------------

islide: Probability Basics (From Neapolitan)

Given a sample space $\Omega$ of the form $\{e_1,\ldots, e_n\}$.

An event $E$ is a subset of $\Omega$\@.

A probability function $P$ assigns a value in $[0, 1]$ to events such that
\begin{enumerate}
\item $P(\{e_1\}) +\ldots + P(\{e_n\}) = 1$, and
\item $P(E) = \Sigma_{e\in E} P(\{e\})$.
\end{enumerate}

Example: For a fair 6-sided dice, the probability $P(i)$ for $1\leq i\leq 6$ is $\frac{1}{6}$.

islide: Bayesian Inference
For two events $E$ and $F$, $P(E | F)$ is the probability of $E$ given $F$, which is
$P(E\cap F)/P(F)$\@.

Events $E$ and $F$ are independent if $P(E | F) = P(E)$ when $P(E) \neq 0$ and $P(F) \neq 0$\@.

$E$ and $F$ are conditionally independent under $G$, if $P(E | F\cap G) = P(E | G)$, when
$P(E | G)$ and $P(F | G)$ are non-zero.

slide: Bayes Theorem (Wikipedia)

Bayes' theorem relates the conditional and marginal probabilities of
events A and B, where B has a non-vanishing probability:
\begin{center}
    $P(A|B) = {\displaystyle \frac{P(B | A)\, P(A)}{P(B)}}$.
\end{center}

Each term in Bayes' theorem has a conventional name:
\begin{itemize}
\item $P(A)$ is the prior or marginal probability of $A$.
\item $P(A|B)$ is the conditional or posterior probability of $A$, given $B$.
\item $P(B|A)$ is the conditional probability of $B$ given $A$. It is also
called the likelihood.
\item $P(B)$ is the prior or marginal probability of $B$; acts as a
normalizing constant.
\end{itemize}

islide: Logic and Probability (Wikipedia)

Medical diagnosis offers a simple example of Bayesian reasoning.

We have a test for a disease that returns positive or negative results. 

If the patient has the disease, the test is positive  with probability $.99$.

If the patient does not have the disease, the test is positive with probability $.05$.

A patient has the disease with probability $.001$.

What is the probability that a patient with a positive test has the disease?

$P(D | pos) = P(pos | D)  P(D)/P(pos) =
.99 \times .001/ (.99\times .001 + .05 \times .999) = 99/5094$

islide: Bayes Nets
Bayes nets are an instance of graphical models
for large-scale Bayesian inference.

A graphical model is one where the nodes represent
random variables and the absence of edges corresponds
to conditional independence. 

Bayes nets are directed, whereas Markov Logic Networks (a.k.a. Markov
Random Fields) are undirected.

In a Bayes Net, each node has a probability distribution
conditional on the valuation of the parent nodes.

A Bayes Net can be used to compute joint probability distributions $P(x_1,
\ldots, x_n)$ by taking each individual variable $X_i$, its parents
$\pi_i$ and the valuation of its parents $X_{\pi_i} = x_{\pi_i}$ as $\Pi_i
P(X_i = x_i | X_{\pi_i} = x_{\pi_i})$\@.

It can also be used for conditional inference to compute the probability
that $\ol{X} = \ol{x}$ given $\ol{Y} = \ol{y}$.

islide: Markov Chain Monte Carlo (MCMC)

Markov chain Monte Carlo (MCMC) methods are a class of algorithms for
sampling from probability distributions

They are based on constructing a Markov chain that has the desired distribution as
its equilibrium distribution.

The state of the chain after a large number of steps is then used as a
sample from the desired distribution.

The quality of the sample improves as a function of the number of steps.

The most common application of these algorithms is numerically calculating
multi-dimensional integrals.

islide: Random Walk Algorithms

A na\"{i}ve implementation of a random walk will make small steps, with no
tendency to proceed in any direction.  Easy to implement, but can take a
long time to cover the space.

Metropolis-Hastings Generates a random walk using a proposal density and a
method for rejecting proposed moves.

Gibbs sampling requires that all the conditional distributions of the
target distribution can be sampled exactly.  When this holds, no 'tuning'
is needed.

Slice sampling alternates sampling in the vertical direction with
sampling from the horizontal `slice' defined by the current vertical
position.

Multiple-try Metropolis is a variation of the Metropolis-Hastings
algorithm that allows multiple trials at each point.

Many variations: Successive over-relaxation, Hybrid
Monte Carlo, Langevin MCMC, Reversible jump ...

islide: Gibbs Sampling
Bayesian inference on a large network is hard,
sampling approaches are used to find stationary
probabilities over a Markov Chain.

Gibbs sampling is one way to construct a Markov chain
and a sample sequence.

Stationary probability corresponds to the joint distribution.

Suppose we have to construct a distribution over two variables
$X$ and $Y$. 

Start with a seed $y_0$.

Then pick $x_0$ by sampling according to $P(X = x | Y = y_0)$.

Then pick $y_1$ according to $P(Y = y | X = x_0)$.

This is repeated to build a sequence $\pair{\pair{x_0, y_0},\ldots}$.

For $n$ random variables, each step picks an assignment for one variable
$X_i$ according to 
$P(X_i = x'_i | \bigwedge_{j<i} X_j = x'_j \wedge \bigwedge_{j>i} X_j = x_j)$.  

islide: Markov Logic Networks: MPE

We want to compute the most likely $y$ such that $Y = y$
given $X = x$, where we have some constraints $C_i$ each with
weight $w_i$\@.  

This is obtained by maximizing $P(Y=y | X=x)$
which is proportional to exponentiation of $\Sigma_i w_i C_i(x, y)$,
the sum of the weights of the satisfiable formulas.

Weighted MAXSAT can compute the MPE.

<Example>

islide: Markov Logics: Marginal Probabilities
Now, given some constraint $C$,  we want to compute
$P(C | X = x)$ over a Markov Logic Network.

<Example>

islide: What is PCE?

PCE is based on Markov Logic, and uses the MCSAT and Lazy MCSAT methods to
compute marginal probabilities.

MCSAT and Lazy MCSAT are variants of Markov Chain Monte Carlo (MCMC)
sampling.

The input language consists of sorts, constants,
direct predicates and indirect predicates, facts, and weighted rules.

The MCSAT inference averages the probabilities over a sequence of random models
generated using SampleSAT.  

islide: PCE Inference: MCSAT
MCSAT computes marginal probabilities of atoms and query instances over
by generating a sequence of random models over all the ground atoms. 

In the initialization step, we first apply a closed world assumption to the
direct atoms (atoms with direct predicates): atoms that are not asserted
as facts are assumed false.

The ground atoms are then assigned a truth value (using WalkSAT)
that satisfies all the hard constraints (rules with MAX weight).

This yields an initial model $M_0$.

Each subsequent $M_{i+1}$ is generated from $M_i$ by selecting the rule
groundings satisfied in $M_i$; discarding some of these rule groundings based on
the weight; and using SampleSAT to build a model satisfying the remaining ones.

We only retain the satisfaction counts for each atom/query formula instance,
and not the models themselves.

islide: WalkSAT, MaxWalkSAT, and SampleSAT
WalkSAT starts with a random truth assignment.

It repeatedly (max\_flips times) picks a random unsatisfied clause and flips
the truth assignment for a literal in this clause.

Otherwise, it tries to start with a different random truth assignment.

MaxWalkSAT the clauses have weights and we would like to find the assignment
that maximizes the weight. 

The literal to be flipped is either randomly (with probability $p$)
chosen from the unsatisfied clause, or we pick the flip that has the greatest
cost differential.

SampleSAT mixes simulated annealing steps where a single randomly chosen
atom is flipped, with MaxWalkSAT steps (where a literal in a randomly chosen
unsatisfied clause is flipped).

slide: WalkSAT Algorithm (Selman et al. 1996)

\begin{tabbing}
Wa\=lkSAT(\textit{clauses}, \textit{max-tries}, \textit{max-flips}, \textit{p})\\
\>\textbf{fo}\=\textbf{r} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{max-tries} \textbf{do}\\
\>\>  \textit{solution} = random truth assignment\\
\>\>  \textbf{fo}\=\textbf{r} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{max-flips} \textbf{do}\\
\>\>\>    \textbf{if}\= \ all \textit{clauses} satisfied \textbf{then}\\
\>\>\>\>      \textbf{return} \textit{solution}\\
\>\>\>    \textit{c} $\leftarrow$ random unsatisfied clause\\
\>\>\>    \textbf{with probability} \textit{p}\\
\>\>\>\>      flip a random variable in \textit{c}\\
\>\>\>    \textbf{else}\\
\>\>\>\>      fli\=p variable in \textit{c} that maximizes\\
\>\>\>\>\>        number of satisfied \textit{clauses}\\
\> \textbf{return} failure\\
\end{tabbing}

slide: MaxWalkSAT Algorithm (Kautz et al. 1997)

\begin{tabbing}
Ma\=xWalkSAT(\textit{clauses}, \textit{max-tries}, \textit{max-flips},
\textit{p}, \textcolor{red}{\textit{thres}})\\
\>\textbf{fo}\=\textbf{r} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{max-tries} \textbf{do}\\
\>\>  \textit{solution} = random truth assignment\\
\>\>  \textbf{fo}\=\textbf{r} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{max-flips} \textbf{do}\\
\>\>\>    \textbf{if}\= \ \textcolor{red}{$\Sigma$ weight(sat. \textit{clauses}) $>$ \textit{thres}} \textbf{then}\\
\>\>\>\>      \textbf{return} \textit{solution}\\
\>\>\>    \textit{c} $\leftarrow$ random unsatisfied clause\\
\>\>\>    \textbf{with probability} \textit{p}\\
\>\>\>\>      flip a random variable in \textit{c}\\
\>\>\>    \textbf{else}\\
\>\>\>\>      fli\=p variable in \textit{c} that maximizes\\
\>\>\>\>\>        \textcolor{red}{$\Sigma$ weight(sat. \textit{clauses})}\\
\> \textbf{return} failure, \textcolor{red}{best \textit{solution} found}\\
\end{tabbing}

slide: SampleSAT (Wei et al. 2004)
\begin{tabbing}
Sa\=mpleSAT(\textit{clauses}, \textit{max-tries}, \textit{max-flips},
\textit{p}, \textit{thres}, \textcolor{red}{\textit{sa-p}, \textit{sa-temp}})\\
\>\textbf{fo}\=\textbf{r} \textit{i} $\leftarrow$ 1 \textbf{to} \textit{max-tries} \textbf{do}\\
\>\>  \textit{solution} = random truth assignment\\
\>\>  \textbf{fo}\=\textbf{r} \textit{j} $\leftarrow$ 1 \textbf{to} \textit{max-flips} \textbf{do}\\
\>\>\>    \textcolor{red}{\textbf{wi}}\=\textcolor{red}{\textbf{th probability} \textit{sa-p}}\\
\>\>\>\>    \textbf{if}\= \ $\Sigma$ weight(sat. \textit{clauses}) $>$ \textit{thres} \textbf{then}\\
\>\>\>\>\>      \textbf{return} \textit{solution}\\
\>\>\>\>    \textit{c} $\leftarrow$ random unsatisfied clause\\
\>\>\>\>    \textbf{with probability} \textit{p}\\
\>\>\>\>\>      flip a random variable in \textit{c}\\
\>\>\>\>    \textbf{else}\\
\>\>\>\>\>      fli\=p variable in \textit{c} that maximizes\\
\>\>\>\>\>\>        $\Sigma$ weight(sat. \textit{clauses})\\
\>\>\>   \textcolor{red}{\textbf{else}}\\
\>\>\>\> \textcolor{red}{perform simulated annealing step with \textit{sa-temp}}\\
\> \textbf{return} failure, best \textit{solution} found\\
\end{tabbing}


islide: PCE Input Language

PCE is written in C, and runs interactively, in batch mode, or as an
XML-RPC server.

It is online, new sorts, subsorts, constants, assertions, and rules can be
added at any time.

The interactive version accepts simple declarations.

The XML-RPC server can work with several clients across different
platforms, and accepts JSON objects.

slide: PCE Interactive Commands
Basic commands are:
\begin{alltt}\smaller{\begin{itemize}
\item sort NAME [ '=' '[' INT '..' INT ']' ] ';'
\item subsort NAME NAME ';'
\item predicate ATOM [direct|indirect] ';'
\item const NAME++',' ':' NAME ';'
\item assert ATOM ';'
\item add FORMULA [WEIGHT [SOURCE]] ';'
\item add_clause CLAUSE [NUM [NAME]] ';'
\item ask FORMULA [THRESHOLD [NUMRESULTS]] ';'
\item mcsat ';'
\item mcsat_params [NUM]**',' ';'
\item reset [all | probabilities] ';'
\item dumptable [all | sort | predicate | atom | clause | rule] ';'
\item load STRING ';'
\item help ';'
\item quit ';'
\end{itemize}}
\end{alltt}


aslide: PCE Example: Boy Born on Tuesday

sort Day;
sort Child;
const Mo, Tu, We, Th, Fr, Sa, Su: Day;
const A, B: Child;
predicate boy(Child) indirect;
predicate born_on(Child, Day) indirect;

# Every child must be born on one and only one day
add [c] born_on(c, Mo) or born_on(c, Tu) or born_on(c, We)
     or born_on(c, Th) or born_on(c, Fr) or born_on(c, Sa)
     or born_on(c, Su);
add [c, d1, d2] (born_on(c, d1) and born_on(c, d2)) implies d1 = d2;
add (born_on(A, Tu) and boy(A)) or (born_on(B, Tu) and boy(B));

mcsat_params 100000,,.00001;
ask (boy(A) and boy(B));

islide: PCE Application: Machine Reading

PCE is currently being used in a machine-reading project managed by SRI

FAUST (Flexible Acquisition and Understanding System for Text)

Large project involving SRI, Stanford, PARC, UMass, UIUC, and UWashington

PCE will act as a ``harness'', accepting weighted assertions and rules
from various classifiers and learners

slide: PCE Application: NFL Articles

An early use case for FAUST is a corpus of NFL newspaper articles

\begin{quote}
With Favre throwing the best-looking pinpoint passes this side of Troy
Aikman and with receiver Robert Brooks doing a great impression of Michael
Irvin and with the Packers' defense playing like, well, like themselves,
Green Bay routed Philadelphia, 39 to 13.
\end{quote}

Task is to determine who won and who lost, and what was the final score

slide: PCE Application: NFL Stanford NLP

The Stanford NLP tools generate the following:

\begin{alltt}\smaller\smaller{
EntityMention [type=NFLTeam, objectId=EntityMention6, value="Packers"]
EntityMention [type=NFLTeam, objectId=EntityMention7, value="Green Bay"]
EntityMention [type=NFLTeam, objectId=EntityMention8, value="Philadelphia"]
EntityMention [type=FinalScore, objectId=EntityMention9, value="39"]
EntityMention [type=FinalScore, objectId=EntityMention10, value="13"]

RelationMention [type=teamScoringAll,
  EntityMention [type=FinalScore, objectId=EntityMention9, value="39"]
  EntityMention [type=NFLTeam, objectId=EntityMention6, value="Packers"]
]
RelationMention [type=teamScoringAll,
  EntityMention [type=FinalScore, objectId=EntityMention9, value="39"]
  EntityMention [type=NFLTeam, objectId=EntityMention8, value="Philadelphia"]
]
RelationMention [type=teamScoringAll,
  EntityMention [type=FinalScore, objectId=EntityMention10, value="13"]
  EntityMention [type=NFLTeam, objectId=EntityMention8, value="Philadelphia"]
]
}\end{alltt}

aslide: PCE Application: NFL Sorts and Predicates in PCE

sort objectId;
sort NFLTeam;
sort FinalScore = [0..100];

predicate MentionNFLTeam(objectId, NFLTeam) direct;
predicate MentionFinalScore(objectId, FinalScore) direct;
predicate MentionTeamScoringAll(objectId, objectId) direct;

predicate played(NFLTeam, NFLTeam) indirect;
predicate scored(NFLTeam, FinalScore) indirect;
predicate won(NFLTeam) indirect;

aslide: PCE Application: NFL ``Mentions'' Rules in PCE

add [tm1, tm2, T1, T2] MentionNFLTeam(tm1, T1)
                   and MentionNFLTeam(tm2, T2) and T1 /= T2
    => played(T1, T2) 2.0;

add [sm, tm, S, T] MentionTeamScoringAll(sm, tm)
         and MentionFinalScore(sm, S)
         and MentionNFLTeam(tm, T)
    => scored(T, S) 1.0;

aslide: PCE Application: NFL Game Rules in PCE

add [T] ~played(T, T);
add [T1, T2] played(T1, T2) implies played(T2, T1);
add [T1, T2] played(T1, T2) and won(T1) implies ~won(T2);

add [T1, T2, S1, S2]
played(T1, T2) and scored(T1, S1) and scored(T2, S2)
  and (S1 > S2) implies won(T1);

add [T1, T2, S1, S2]
played(T1, T2) and scored(T1, S1) and scored(T2, S2)
  and ~(S2 > S1) implies ~won(T2) ;

add [T, S1, S2] scored(T, S1) and (S1 > S2)
 implies ~scored(T, S2);

aslide: PCE Application: NFL Facts (from Stanford Output)
\smaller{
const EntityMention6: objectId;
const EntityMention7: objectId;
const EntityMention8: objectId;
const EntityMention9: objectId;
const EntityMention10: objectId;
const Packers: NFLTeam;
const GreenBay: NFLTeam;
const Philadelphia: NFLTeam;
assert MentionNFLTeam(EntityMention6, Packers);
assert MentionNFLTeam(EntityMention7, GreenBay);
assert MentionNFLTeam(EntityMention8, Philadelphia);
assert MentionFinalScore(EntityMention9, 39);
assert MentionFinalScore(EntityMention10, 13);

assert MentionTeamScoringAll(EntityMention9, EntityMention6);
assert MentionTeamScoringAll(EntityMention9, EntityMention8);
assert MentionTeamScoringAll(EntityMention10, EntityMention8);

ask [T1, T2] won(T1) and ~won(T2) .1;
}

slide: PCE Application: NFL Result
\begin{alltt}\smaller\smaller{% mcsat ../examples/football
Loading ../examples/football
Input from file ../examples/football
Setting MCSAT parameters:
 max_samples was 100, now 1000

6 results:
[T1 <- GreenBay, T2 <- Philadelphia] 0.385:
     (won(GreenBay)) & (~won(Philadelphia))
[T1 <- GreenBay, T2 <- Packers] 0.358:
     (won(GreenBay)) & (~won(Packers))
[T1 <- Packers, T2 <- Philadelphia] 0.348:
     (won(Packers)) & (~won(Philadelphia))
[T1 <- Packers, T2 <- GreenBay] 0.319:
     (won(Packers)) & (~won(GreenBay))
[T1 <- Philadelphia, T2 <- Packers] 0.291:
     (won(Philadelphia)) & (~won(Packers))
[T1 <- Philadelphia, T2 <- GreenBay] 0.289:
     (won(Philadelphia)) & (~won(GreenBay))
QUIT reached, exiting read_eval_print_loop
}\end{alltt}

Took over 2 minutes on a 64-bit intel

slide: PCE Application: NFL Lazy Result

\begin{alltt}\smaller\smaller{% mcsat ../examples/football --lazy=true
Loading ../examples/football
Input from file ../examples/football
Setting MCSAT parameters:
 max_samples was 100, now 1000

6 results:
[T1 <- GreenBay, T2 <- Philadelphia] 0.280:
     (won(GreenBay)) & (~won(Philadelphia))
[T1 <- GreenBay, T2 <- Packers] 0.273:
     (won(GreenBay)) & (~won(Packers))
[T1 <- Packers, T2 <- Philadelphia] 0.258:
     (won(Packers)) & (~won(Philadelphia))
[T1 <- Philadelphia, T2 <- Packers] 0.252:
     (won(Philadelphia)) & (~won(Packers))
[T1 <- Philadelphia, T2 <- GreenBay] 0.251:
     (won(Philadelphia)) & (~won(GreenBay))
[T1 <- Packers, T2 <- GreenBay] 0.250:
     (won(Packers)) & (~won(GreenBay))
QUIT reached, exiting read_eval_print_loop
}\end{alltt}

Probabilities are somewhat different, but time is $<$ a second.

slide: Relation to Other Models



Bayes Networks



islide: Related Work

Alchemy (P. Domingos, Univ. of Washington)

Markov TheBeast (S. Riedel)

islide: Future Work

Add conditionals

Add functional properties, e.g., bijective, etc.

Allow restricted formulas for direct predicates

Allow probabilities to be given for weights

Modularize, allowing composition of different samplings

Allow non-Boolean Random Variables

slide: Conclusions

